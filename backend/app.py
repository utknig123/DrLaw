#supabase working 
#google auth not working 
#version 1 final(deployable)

from flask_cors import CORS
from flask import Flask, request, jsonify, render_template, redirect, url_for, session, flash
from authlib.integrations.flask_client import OAuth
import os
import json
import nltk
import numpy as np
import PyPDF2
from sentence_transformers import SentenceTransformer
import faiss
import google.generativeai as genai
import nltk.data
import time
import requests
import urllib.parse
from werkzeug.security import generate_password_hash, check_password_hash
from functools import wraps
from supabase import create_client, Client
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize Flask app
app = Flask(__name__)
# Prefer configured secret for stable sessions across restarts
app.secret_key = os.environ.get("FLASK_SECRET_KEY", os.urandom(24))

# CORS configuration (comma-separated origins in CORS_ORIGINS)
cors_origins_env = os.environ.get("CORS_ORIGINS", "http://localhost:10000,https://drlaw.onrender.com,https://*.vercel.app")
cors_origins = [o.strip() for o in cors_origins_env.split(",") if o.strip()]
CORS(app, supports_credentials=True, origins=cors_origins)

# Supabase Configuration
url: str = os.environ.get("SUPABASE_URL")
key: str = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(url, key)

# Get URLs from environment variables
FRONTEND_URL = os.environ.get('FRONTEND_URL', 'https://drlaw.onrender.com')
BACKEND_URL = os.environ.get('BACKEND_URL', 'https://drlaw.onrender.com')

# Initialize OAuth
oauth = OAuth(app)
google = oauth.register(
    name='google',
    client_id=os.environ.get('GOOGLE_CLIENT_ID', ''),
    client_secret=os.environ.get('GOOGLE_CLIENT_SECRET', ''),
    access_token_url='https://accounts.google.com/o/oauth2/token',
    access_token_params=None,
    authorize_url='https://accounts.google.com/o/oauth2/auth',
    authorize_params=None,
    api_base_url='https://www.googleapis.com/oauth2/v1/',
    client_kwargs={'scope': 'openid email profile',
                   # Redirect to backend callback to complete OAuth
                   'redirect_uri': f"{BACKEND_URL}/login/google/authorize"},
)

# Initialize the RAG system
API_KEY = os.environ.get("GEMINI_API_KEY") or None

# Translation function using direct API calls
def translate_text(text, dest_language='hi', src_language='en'):
    """
    Simple translation function using Google Translate API directly
    """
    try:
        # URL encode the text
        encoded_text = urllib.parse.quote(text)
        
        # Google Translate API endpoint
        url = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl={src_language}&tl={dest_language}&dt=t&q={encoded_text}"
        
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            # Parse the JSON response
            translation_data = response.json()
            if translation_data and len(translation_data) > 0:
                translated_text = translation_data[0][0][0]
                return translated_text
        
        return text  # Return original text if translation fails
    except Exception as e:
        print(f"Translation error: {e}")
        return text  # Return original text on any error

# Language codes and their names
LANGUAGES = {
    'en': 'English', 'hi': 'Hindi', 'bn': 'Bengali', 'te': 'Telugu', 'mr': 'Marathi',
    'ta': 'Tamil', 'gu': 'Gujarati', 'kn': 'Kannada', 'ml': 'Malayalam', 'pa': 'Punjabi', 'or': 'Odia'
}

class PDFProcessor:
    """Simple PDF text extractor"""
    def extract_text(self, pdf_path: str) -> str:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page in reader.pages:
                # handle pages where extract_text() may return None
                page_text = page.extract_text() or ""
                text += page_text + "\n"
        return text

class TextChunker:
    """Splits text into chunks"""
    def __init__(self, chunk_size: int = 500):  # Reduced chunk size for memory
        self.chunk_size = chunk_size
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            nltk.download('punkt', quiet=True)
    
    def chunk_text(self, text: str) -> list:
        sentences = nltk.sent_tokenize(text)
        chunks = []
        current_chunk = ""
        for sentence in sentences:
            if len(current_chunk) + len(sentence) > self.chunk_size:
                chunks.append(current_chunk)
                current_chunk = sentence
            else:
                current_chunk += " " + sentence if current_chunk else sentence
        if current_chunk:
            chunks.append(current_chunk)
        return chunks

class RAGSystem:
    """RAG system with memory optimization"""
    def __init__(self, api_key: str = None, supabase_client=None):
        if api_key is None:
            api_key = API_KEY
        
        # Lazy loading components
        self.pdf_processor = None
        self.chunker = None
        self.embedding_model = None
        self.llm = None
        self.index = None
        self.chunks = []
        self.is_trained = False
        self.supabase = supabase_client
        self.pdf_bucket = "legal_pdfs"
        self.api_key_missing = False
        
        # Storage setup
        self.storage_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "storage")
        os.makedirs(self.storage_dir, exist_ok=True)
        self.index_path = os.path.join(self.storage_dir, "faiss_index.bin")
        self.metadata_path = os.path.join(self.storage_dir, "chunks_metadata.json")
        
        # Load or create index
        self.load_or_create_index()
        
        # Initialize API key only
        try:
            if not api_key:
                self.api_key_missing = True
                print("Warning: GEMINI_API_KEY not set. Set GEMINI_API_KEY in environment.")
            else:
                genai.configure(api_key=api_key)
        except Exception as e:
            print(f"Warning: genai init failed: {e}")
    
    def load_pdf_processor(self):
        """Lazy load PDF processor"""
        if self.pdf_processor is None:
            self.pdf_processor = PDFProcessor()
    
    def load_chunker(self):
        """Lazy load chunker"""
        if self.chunker is None:
            self.chunker = TextChunker()
    
    def load_embedding_model(self):
        """Lazy load embedding model - memory intensive"""
        if self.embedding_model is None:
            print("Loading sentence transformer model...")

            # Force specific model format to prevent downloading all formats
            #os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'
            #os.environ['TRANSFORMERS_OFFLINE'] = '0'

            self.embedding_model = SentenceTransformer('paraphrase-albert-small-v2'
                                                      # device='cpu'
                                                       )
                                                        # Smaller model
            print("Model loaded successfully")
    
    def load_llm(self):
        """Lazy load LLM"""
        if self.api_key_missing:
            raise RuntimeError("GEMINI_API_KEY is missing. Please set it in your environment.")
        if self.llm is None:
            self.llm = genai.GenerativeModel('gemini-2.0-flash')
    
    def load_or_create_index(self):
        """Load existing index and chunks or create new ones"""
        # NUCLEAR OPTION: Always create fresh index
        try:
            if os.path.exists(self.index_path):
                os.remove(self.index_path)
            if os.path.exists(self.metadata_path):
                os.remove(self.metadata_path)
        except:
            pass
        
        # Always create new index with correct dimensions
        self.load_embedding_model()
        test_embedding = self.embedding_model.encode(["test"])
        dimension = test_embedding.shape[1]
        
        nlist = 50
        quantizer = faiss.IndexFlatL2(dimension)
        self.index = faiss.IndexIVFFlat(quantizer, dimension, nlist)
        self.chunks = []
        print(f"Created fresh FAISS index with dimension: {dimension}")
    
    def save_index_and_chunks(self):
        """Save the FAISS index and chunks metadata"""
        try:
            faiss.write_index(self.index, self.index_path)
            with open(self.metadata_path, 'w') as f:
                json.dump(self.chunks, f)
        except Exception as e:
            print(f"Error saving index: {e}")
    
    def download_and_process_pdf(self, pdf_name: str) -> str:
        """Download PDF from Supabase and process it with memory optimization"""
        try:
            self.load_pdf_processor()
            self.load_chunker()
            self.load_embedding_model()
            
            # Check if already processed
            if any(pdf_name in chunk.get('source', '') for chunk in self.chunks):
                return f"PDF {pdf_name} was already processed."
            
            # Download PDF from Supabase
            print(f"Downloading {pdf_name} from Supabase...")
            pdf_data = self.supabase.storage.from_(self.pdf_bucket).download(pdf_name)
            
            # Save to temporary file
            temp_path = os.path.join(self.storage_dir, pdf_name)
            with open(temp_path, 'wb') as f:
                f.write(pdf_data)
            
            # Process the PDF
            text = self.pdf_processor.extract_text(temp_path)
            new_chunks = self.chunker.chunk_text(text)
            
            # Process chunks in batches to reduce memory peaks
            batch_size = 5
            for i in range(0, len(new_chunks), batch_size):
                batch_chunks = new_chunks[i:i+batch_size]
                embeddings = self.embedding_model.encode(batch_chunks)
                
                # Train index if needed
                if not self.is_trained and len(embeddings) >= 50:
                    self.index.train(embeddings.astype(np.float32))
                    self.is_trained = True
                
                # Add to index if trained
                if self.is_trained:
                    self.index.add(embeddings.astype(np.float32))
                
                # Add metadata
                chunk_metadata = [{'text': chunk, 'source': pdf_name} for chunk in batch_chunks]
                self.chunks.extend(chunk_metadata)
            
            self.save_index_and_chunks()
            
            # Clean up temporary file
            os.remove(temp_path)
            
            return f"Successfully processed {len(new_chunks)} chunks from {pdf_name}"
            
        except Exception as e:
            # Clean up if temp file was created
            temp_path = os.path.join(self.storage_dir, pdf_name)
            if os.path.exists(temp_path):
                os.remove(temp_path)
            return f"Error processing PDF from Supabase: {str(e)}"
    
    def query(self, question: str, conversation_history=None, language='en', top_k: int = 3) -> str:
        """Query the system with conversation history and language support"""
        try:
            if self.api_key_missing:
                return ("Error generating answer: Missing GEMINI_API_KEY. "
                        "Set GEMINI_API_KEY in your .env or Render env vars, then restart.")
            self.load_embedding_model()
            self.load_llm()
            
            # Get relevant chunks
            query_embedding = self.embedding_model.encode([question])
            scores, indices = self.index.search(query_embedding.astype(np.float32), top_k)
            
            # Get context from relevant chunks
            context = " ".join([self.chunks[i]['text'] for i in indices[0] if i < len(self.chunks)])
            
            # Format conversation history
            conversation_context = ""
            if conversation_history:
                conversation_context = "Previous conversation:\n"
                for message in conversation_history:
                    role = "User" if message.get('role') == 'user' else "DrLAW"
                    conversation_context += f"{role}: {message.get('content')}\n"
            
            # Generate answer using Gemini
            output_language = LANGUAGES.get(language, 'English')
            prompt = f"""You are DrLAW, a legal AI advisor. Your task is to provide detailed legal advice based on the following context:

CONTEXT FROM LEGAL DOCUMENTS:
{context}

{conversation_context}

Current Question: {question}

Format your response with clear sections. Use HTML formatting. Include:
1. Brief greeting and introduction
2. Clear, concise answer (200-300 words)
3. Detailed explanation with HTML tables for:
   - Legal Roadmap
   - Required Documentation  
   - Applicable Laws
4. Brief conclusion

Response should be in {output_language}."""

            response = self.llm.generate_content(prompt)
            answer_text = response.text
            
            # Translate if needed
            if language != 'en':
                answer_text = translate_text(answer_text, language, 'en')
            
            return answer_text
        except Exception as e:
            return f"Error generating answer: {str(e)}"

# Initialize RAG system with Supabase client
rag = RAGSystem(api_key=API_KEY, supabase_client=supabase)

# Process PDFs from Supabase storage at startup
def initialize_rag_system():
    """Initialize RAG system by processing PDFs from Supabase"""
    print("Initializing RAG system...")
    
    pdf_files = ["constitution.pdf"]
    
    for pdf_file in pdf_files:
        print(f"Processing {pdf_file} from Supabase...")
        result = rag.download_and_process_pdf(pdf_file)
        print(result)

# Database helper functions
def get_user_by_email(email):
    try:
        response = supabase.table("users").select("*").eq("email", email).execute()
        return response.data[0] if response.data else None
    except Exception as e:
        print(f"Error getting user by email: {e}")
        return None

def create_user(username, email, password_hash=None, google_id=None):
    try:
        user_data = {"username": username, "email": email}
        if password_hash:
            user_data["password_hash"] = password_hash
        if google_id:
            user_data["google_id"] = google_id
            
        response = supabase.table("users").insert(user_data).execute()
        return response.data[0]["user_id"]
    except Exception as e:
        print(f"Error creating user: {e}")
        return None

def save_chat(user_id, question, answer):
    if not user_id:
        raise ValueError("user_id is required")
    try:
        chat_data = {"user_id": user_id, "question": question, "answer": answer}
        supabase.table("chats").insert(chat_data).execute()
    except Exception as e:
        print(f"Error saving chat: {e}")
        raise

def get_chat_history(user_id):
    try:
        response = supabase.table("chats").select("*").eq("user_id", user_id).order("timestamp", desc=True).execute()
        return response.data
    except Exception as e:
        print(f"Error getting chat history: {e}")
        return []

# Authentication decorator
def login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

# Flask routes
@app.route('/')
def index():
    if 'user_id' in session:
        return render_template('index.html')
    return render_template('front.html')

@app.route('/login', methods=['GET', 'POST'])
def login():
    if 'user_id' in session:
        return redirect(url_for('index'))
    
    if request.method == 'POST':
        email = request.form.get('email')
        password = request.form.get('password')
        user = get_user_by_email(email)
        
        if user and check_password_hash(user['password_hash'], password):
            session['user_id'] = user['user_id']
            session['username'] = user['username']
            flash('Logged in successfully!', 'success')
            return redirect(url_for('index'))
        else:
            flash('Invalid email or password', 'danger')
    
    return render_template('login.html')

@app.route('/signup', methods=['GET', 'POST'])
def signup():
    if 'user_id' in session:
        return redirect(url_for('index'))
        
    if request.method == 'POST':
        username = request.form.get('username')
        email = request.form.get('email')
        password = request.form.get('password')
        
        if get_user_by_email(email):
            flash('Email already registered', 'danger')
            return redirect(url_for('signup'))
        
        try:
            password_hash = generate_password_hash(password)
            user_id = create_user(username, email, password_hash)
            session['user_id'] = user_id
            session['username'] = username
            flash('Account created successfully!', 'success')
            return redirect(url_for('index'))
        except Exception as e:
            flash('Error creating account', 'danger')
    
    return render_template('front.html')

@app.route('/login/google')
def google_login():
    # Ensure the redirect URI matches the one registered in Google Console and client config
    redirect_uri = f"{BACKEND_URL}/login/google/authorize"
    return google.authorize_redirect(redirect_uri)

@app.route('/login/google/authorize')
def google_authorize():
    try:
        token = google.authorize_access_token()
        user_info = google.get('userinfo').json()
        
        response = supabase.table("users").select("*").eq("google_id", user_info['id']).execute()
        user = response.data[0] if response.data else None
        
        if not user:
            response = supabase.table("users").select("*").eq("email", user_info['email']).execute()
            user = response.data[0] if response.data else None
            
            if user:
                supabase.table("users").update({"google_id": user_info['id']}).eq("user_id", user['user_id']).execute()
            else:
                username = user_info.get('name', user_info['email'].split('@')[0])
                user_id = create_user(username=username, email=user_info['email'], google_id=user_info['id'])
                user = {'user_id': user_id, 'username': username}
        
        session['user_id'] = user['user_id']
        session['username'] = user['username']
        flash('Logged in with Google successfully!', 'success')
        return redirect(url_for('index'))
    
    except Exception as e:
        flash('Error logging in with Google', 'danger')
        return redirect(url_for('login'))

@app.route('/logout', methods=['GET','POST'])
def logout():
    session.clear()
    # On POST from frontend fetch, return JSON; on GET (direct link), redirect
    if request.method == 'POST':
        return jsonify({'status': 'ok'})
    flash('Logged out successfully', 'success')
    return redirect(url_for('login'))

@app.route('/ask', methods=['POST'])
@login_required
def ask():
    # Double check session even with @login_required decorator
    if 'user_id' not in session:
        return jsonify({'error': 'Authentication required'}), 401
        
    data = request.json
    question = data.get('question')
    language = data.get('language', 'en')
    conversation_history = data.get('conversation_history', [])

    if not question:
        return jsonify({'error': 'No question provided'}), 400
    
    try:
        answer = rag.query(question, conversation_history, language)
        save_chat(session.get('user_id'), question, answer)
    except ValueError as e:
        # Handle missing user_id
        return jsonify({'error': str(e)}), 401
    except Exception as e:
        # Handle other errors (DB errors, etc)
        print(f"Error in /ask route: {e}")
        return jsonify({'error': 'Internal server error'}), 500
    
    return jsonify({'question': question, 'answer': answer, 'language': language})

@app.route('/chat/history')
@login_required
def chat_history():
    history = get_chat_history(session['user_id'])
    return jsonify([dict(row) for row in history])

# Initialize RAG system on app startup - PROCESS PDF FROM SUPABASE
with app.app_context():
    initialize_rag_system()

# fix main guard
if __name__ == '__main__':
    port = int(os.environ.get("PORT", 10000))
    app.run(host='0.0.0.0', port=10000)